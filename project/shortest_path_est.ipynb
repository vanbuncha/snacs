{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import choice\n",
    "from random import sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of directed edges in dblp.tsv: 1049866\n",
      "number of directed nodes in dblp.tsv: 317080\n"
     ]
    }
   ],
   "source": [
    "# grap init\n",
    "G_dblp = nx.Graph()\n",
    "\n",
    "\n",
    "# dblp.tsv\n",
    "with open('data/dblp/com-dblp/out.com-dblp.tsv', 'r') as file:\n",
    "    for line in file:\n",
    "        source, target = line.strip().split(' ')\n",
    "        G_dblp.add_edge(int(source), int(target))\n",
    "\n",
    "num_edges = G_dblp.number_of_edges()\n",
    "num_nodes = G_dblp.number_of_nodes()\n",
    "\n",
    "\n",
    "print(\"number of directed edges in dblp.tsv:\", num_edges)\n",
    "print(\"number of directed nodes in dblp.tsv:\", num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a fraction of graph for teting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\n",
      "Number of edges in subgraph: 72769\n",
      "Number of nodes in subgraph: 15854\n"
     ]
    }
   ],
   "source": [
    "# Define the fraction of nodes to include in the subgraph \n",
    "fraction = 0.05\n",
    "\n",
    "# Get a subset of nodes based on the fraction\n",
    "subset_nodes = list(G_dblp.nodes())[:int(fraction * len(G_dblp))]\n",
    "\n",
    "# Create a subgraph using the subset of nodes\n",
    "subgraph_dblp = G_dblp.subgraph(subset_nodes)\n",
    "\n",
    "# Get the number of edges and nodes in the subgraph\n",
    "num_edges_sub = subgraph_dblp.number_of_edges()\n",
    "num_nodes_sub = subgraph_dblp.number_of_nodes()\n",
    "\n",
    "# subgraph info:\n",
    "# print(\"Subgraph Nodes:\", subgraph_dblp.nodes())\n",
    "# print(\"Subgraph Edges:\", subgraph_dblp.edges())\n",
    "print(\"-----\" + \"\\n\")\n",
    "print(\"Number of edges in subgraph:\", num_edges_sub)\n",
    "print(\"Number of nodes in subgraph:\", num_nodes_sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing random nodes for landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark List: [281365, 268588, 197617, 14306, 116569, 101195, 108644, 21442, 261569, 265311, 57815, 227744, 226747, 293167, 129730, 156599, 243827, 9209, 43918, 37144]\n"
     ]
    }
   ],
   "source": [
    "def generate_landmark_list(graph, num_landmarks=20):\n",
    "    \"\"\"\n",
    "    Generate a list of random landmarks from the given graph.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: NetworkX graph\n",
    "    - num_landmarks: Number of landmarks to generate (default is 20)\n",
    "\n",
    "    Returns:\n",
    "    - landmark_list: List of random landmarks\n",
    "    \"\"\"\n",
    "    landmark_list = []\n",
    "\n",
    "    for i in range(num_landmarks):\n",
    "        random_node = choice(list(graph.nodes()))\n",
    "        if random_node not in landmark_list:\n",
    "            landmark_list.append(random_node)\n",
    "\n",
    "    return landmark_list\n",
    "\n",
    "# Example usage:\n",
    "num_landmarks = 20\n",
    "\n",
    "landmark_list = generate_landmark_list(G_dblp, num_landmarks)\n",
    "print(\"Landmark List:\", landmark_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating each node's degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The degree of node 3336 is 343\n",
      "The degree of node 3345 is 296\n",
      "The degree of node 167 is 290\n",
      "The degree of node 14690 is 269\n",
      "The degree of node 13941 is 264\n",
      "The degree of node 30095 is 244\n",
      "The degree of node 13842 is 230\n",
      "The degree of node 865 is 227\n",
      "The degree of node 3298 is 225\n",
      "The degree of node 13811 is 221\n",
      "The degree of node 15326 is 219\n",
      "The degree of node 3346 is 218\n",
      "The degree of node 3326 is 218\n",
      "The degree of node 1827 is 215\n",
      "The degree of node 1833 is 215\n",
      "The degree of node 13953 is 215\n",
      "The degree of node 45 is 208\n",
      "The degree of node 7227 is 207\n",
      "The degree of node 2486 is 201\n",
      "The degree of node 6319 is 201\n"
     ]
    }
   ],
   "source": [
    "# Define the number of top nodes to print\n",
    "N = 20\n",
    "\n",
    "# Get the top nodes with the highest degree\n",
    "top_nodes_degree = sorted(G_dblp.nodes(), key=G_dblp.degree, reverse=True)[:N]\n",
    "\n",
    "# Print the degree for each of the top nodes\n",
    "for node in top_nodes_degree:\n",
    "    node_degree = G_dblp.degree(node)\n",
    "    print(f\"The degree of node {node} is {node_degree}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate each's node closeness centrality (approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_closeness_centrality(graph, num_seeds=10):\n",
    "    # Select a sample of random seed nodes\n",
    "    seed_nodes = sample(graph.nodes(), num_seeds)\n",
    "\n",
    "    # Initialize the closeness centrality dictionary\n",
    "    approx_closeness_centrality = {node: 0.0 for node in graph.nodes()}\n",
    "\n",
    "    # Perform BFS computations from each seed node\n",
    "    for seed_node in seed_nodes:\n",
    "        distances = nx.single_source_shortest_path_length(graph, seed_node)\n",
    "        for node, distance in distances.items():\n",
    "            approx_closeness_centrality[node] += distance\n",
    "\n",
    "    # Normalize the closeness centrality by the number of seed nodes\n",
    "    for node in graph.nodes():\n",
    "        approx_closeness_centrality[node] /= num_seeds\n",
    "\n",
    "    return approx_closeness_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage on fraction of graph\n",
    "# subgraph_dblp = nx.subgraph(G_dblp, subset_nodes)  \n",
    "# num_seeds = 100  # Adjust as needed\n",
    "\n",
    "# # Calculate approximate closeness centrality for each node\n",
    "# approx_closeness_centrality = approximate_closeness_centrality(subgraph_dblp, num_seeds)\n",
    "\n",
    "# # Count the number of nodes with zero closeness centrality\n",
    "# num_nodes_with_zero_centrality = sum(1 for centrality in approx_closeness_centrality.values() if centrality == 0)\n",
    "\n",
    "# # Get the bottom nodes with the lowest approximate closeness centrality and non-zero centrality\n",
    "# bottom_nodes_closeness = [node for node in sorted(approx_closeness_centrality, key=approx_closeness_centrality.get) if approx_closeness_centrality[node] > 0][:N]\n",
    "\n",
    "# # Print the approximate closeness centrality for each of the bottom nodes\n",
    "# for node in bottom_nodes_closeness:\n",
    "#     centrality = approx_closeness_centrality[node]\n",
    "#     print(f\"The approximate closeness centrality of node {node} is {centrality}\")\n",
    "\n",
    "# # Print the count of nodes with zero closeness centrality\n",
    "# print(f\"Number of nodes with zero closeness centrality: {num_nodes_with_zero_centrality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/tw9kr3yd4h950rswblzvqc9h0000gn/T/ipykernel_96136/302520595.py:3: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  seed_nodes = sample(graph.nodes(), num_seeds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate closeness centrality of node 167 is 4.65\n",
      "The approximate closeness centrality of node 4306 is 4.7\n",
      "The approximate closeness centrality of node 35572 is 4.7\n",
      "The approximate closeness centrality of node 2021 is 4.75\n",
      "The approximate closeness centrality of node 4807 is 4.75\n",
      "The approximate closeness centrality of node 6341 is 4.75\n",
      "The approximate closeness centrality of node 3330 is 4.75\n",
      "The approximate closeness centrality of node 1972 is 4.75\n",
      "The approximate closeness centrality of node 2175 is 4.75\n",
      "The approximate closeness centrality of node 1830 is 4.8\n",
      "The approximate closeness centrality of node 3336 is 4.8\n",
      "The approximate closeness centrality of node 7430 is 4.8\n",
      "The approximate closeness centrality of node 13842 is 4.8\n",
      "The approximate closeness centrality of node 29720 is 4.8\n",
      "The approximate closeness centrality of node 3300 is 4.8\n",
      "The approximate closeness centrality of node 45 is 4.85\n",
      "The approximate closeness centrality of node 2006 is 4.85\n",
      "The approximate closeness centrality of node 6058 is 4.85\n",
      "The approximate closeness centrality of node 11568 is 4.85\n",
      "The approximate closeness centrality of node 9508 is 4.85\n",
      "Number of nodes with zero closeness centrality: 0\n"
     ]
    }
   ],
   "source": [
    "# Whole graph closeness\n",
    "num_seeds = 20  \n",
    "\n",
    "# Calculate approximate closeness centrality for each node\n",
    "approx_closeness_centrality = approximate_closeness_centrality(G_dblp, num_seeds)\n",
    "\n",
    "# Count the number of nodes with zero closeness centrality\n",
    "num_nodes_with_zero_centrality = sum(1 for centrality in approx_closeness_centrality.values() if centrality == 0)\n",
    "\n",
    "# Get the bottom nodes with the lowest approximate closeness centrality and non-zero centrality\n",
    "bottom_nodes_closeness = [node for node in sorted(approx_closeness_centrality, key=approx_closeness_centrality.get) if approx_closeness_centrality[node] > 0][:N]\n",
    "\n",
    "# Print the approximate closeness centrality for each of the bottom nodes\n",
    "for node in bottom_nodes_closeness:\n",
    "    centrality = approx_closeness_centrality[node]\n",
    "    print(f\"The approximate closeness centrality of node {node} is {centrality}\")\n",
    "\n",
    "# Print the count of nodes with zero closeness centrality\n",
    "print(f\"Number of nodes with zero closeness centrality: {num_nodes_with_zero_centrality}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate each's node betweeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_betweenness_centrality(graph, num_seeds=10):\n",
    "    # Select a sample of random seed nodes\n",
    "    seed_nodes = sample(graph.nodes(), num_seeds)\n",
    "\n",
    "    # Initialize the betweenness centrality dictionary\n",
    "    approx_betweenness_centrality = {node: 0.0 for node in graph.nodes()}\n",
    "\n",
    "    # Perform BFS computations from each seed node and accumulate dependencies\n",
    "    for seed_node in seed_nodes:\n",
    "        paths = nx.single_source_shortest_path(graph, source=seed_node)\n",
    "        dependencies = {node: 0 for node in graph.nodes()}\n",
    "\n",
    "        for path in paths.values():\n",
    "            for node in path[1:-1]:  # Exclude the source and target nodes\n",
    "                dependencies[node] += 1\n",
    "\n",
    "        # Accumulate betweenness centrality using dependencies\n",
    "        for node in graph.nodes():\n",
    "            if node != seed_node:\n",
    "                approx_betweenness_centrality[node] += dependencies[node]\n",
    "\n",
    "    # Normalize the betweenness centrality by the number of seed nodes\n",
    "    for node in graph.nodes():\n",
    "        approx_betweenness_centrality[node] /= num_seeds\n",
    "\n",
    "    return approx_betweenness_centrality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/tw9kr3yd4h950rswblzvqc9h0000gn/T/ipykernel_96136/2477495707.py:3: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  seed_nodes = sample(graph.nodes(), num_seeds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate betweenness centrality of node 19741 is 15975.45\n",
      "The approximate betweenness centrality of node 161387 is 15881.6\n",
      "The approximate betweenness centrality of node 41719 is 15877.35\n",
      "The approximate betweenness centrality of node 133007 is 15872.15\n",
      "The approximate betweenness centrality of node 207952 is 15869.8\n",
      "The approximate betweenness centrality of node 60061 is 15867.05\n",
      "The approximate betweenness centrality of node 19972 is 15862.8\n",
      "The approximate betweenness centrality of node 207430 is 15858.95\n",
      "The approximate betweenness centrality of node 161386 is 15856.65\n",
      "The approximate betweenness centrality of node 112139 is 15855.75\n",
      "The approximate betweenness centrality of node 194301 is 15819.4\n",
      "The approximate betweenness centrality of node 38607 is 15721.75\n",
      "The approximate betweenness centrality of node 1197 is 15706.9\n",
      "The approximate betweenness centrality of node 93135 is 15696.5\n",
      "The approximate betweenness centrality of node 37940 is 15281.95\n",
      "The approximate betweenness centrality of node 10515 is 15171.9\n",
      "The approximate betweenness centrality of node 146160 is 14876.95\n",
      "The approximate betweenness centrality of node 18538 is 14450.55\n",
      "The approximate betweenness centrality of node 8444 is 14380.5\n",
      "The approximate betweenness centrality of node 3330 is 14295.35\n",
      "Number of nodes with zero betweenness centrality: 232285\n"
     ]
    }
   ],
   "source": [
    "# Whole graph betweenness\n",
    "num_seeds = 20\n",
    "\n",
    "# Calculate approximate betweenness centrality for each node\n",
    "approx_betweenness_centrality = approximate_betweenness_centrality(G_dblp, num_seeds)\n",
    "\n",
    "# Count the number of nodes with zero betweenness centrality\n",
    "num_nodes_with_zero_centrality = sum(1 for centrality in approx_betweenness_centrality.values() if centrality == 0)\n",
    "\n",
    "# Get the top nodes with the highest approximate betweenness centrality and non-zero centrality\n",
    "top_nodes_between = [node for node in sorted(approx_betweenness_centrality, reverse=True, key=approx_betweenness_centrality.get) if approx_betweenness_centrality[node] > 0][:N]\n",
    "\n",
    "# Print the approximate betweenness centrality for each of the top nodes\n",
    "for node in top_nodes_between:\n",
    "    centrality = approx_betweenness_centrality[node]\n",
    "    print(f\"The approximate betweenness centrality of node {node} is {centrality}\")\n",
    "\n",
    "# Print the count of nodes with zero betweenness centrality\n",
    "print(f\"Number of nodes with zero betweenness centrality: {num_nodes_with_zero_centrality}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area of repulsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_neighborhood(nodes_to_check, landmarks, graph, k=2):\n",
    "    \"\"\"\n",
    "    Check if any node in nodes_to_check is within the k neighborhood of any landmark.\n",
    "\n",
    "    Parameters:\n",
    "        - nodes_to_check (list): List of nodes to check\n",
    "        - landmarks (list): List of landmark nodes\n",
    "        - graph (NetworkX graph): The graph\n",
    "        - k (int): Neighborhood size (default is 2)\n",
    "\n",
    "    Returns:\n",
    "        - conflicting_nodes (list): List of nodes that are within the k neighborhood of any landmark\n",
    "    \"\"\"\n",
    "    conflicting_nodes = []\n",
    "\n",
    "    for landmark in landmarks:\n",
    "        # Exclude nodes within the k neighborhood of the current landmark\n",
    "        excluded_nodes = set(nx.single_source_shortest_path_length(graph, landmark, cutoff=k).keys())\n",
    "        \n",
    "        # Check for conflicts with nodes_to_check\n",
    "        conflicts = set(nodes_to_check) & excluded_nodes\n",
    "\n",
    "        # Add conflicting nodes to the list\n",
    "        conflicting_nodes.extend(conflicts)\n",
    "\n",
    "    return list(set(conflicting_nodes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks: [261089, 80272, 41075, 106958, 11958, 167282, 139864, 145453, 180338, 260548, 216110, 279046, 3703, 257204, 192959, 81757, 208892, 268068, 253142, 241438]\n"
     ]
    }
   ],
   "source": [
    "# Create a loop to generate random landmarks until there are no conflicts\n",
    "while True:\n",
    "    \n",
    "    landmark_list = generate_landmark_list(G_dblp)\n",
    "    # Check for conflicts between the set of landmarks for each centrality measure\n",
    "    conflicts_degree = check_neighborhood(top_nodes_degree, landmark_list, G_dblp, 2)\n",
    "    conflicts_closeness = check_neighborhood(bottom_nodes_closeness, landmark_list, G_dblp, 2)\n",
    "    conflicts_between = check_neighborhood(top_nodes_between, landmark_list, G_dblp, 2)\n",
    "\n",
    "    # If there are no conflicts for any centrality measure, break out of the loop\n",
    "    if not (conflicts_degree or conflicts_closeness or conflicts_between):\n",
    "        break\n",
    "\n",
    "# Print the final set of landmarks\n",
    "print(\"Landmarks:\", landmark_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snacs_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
